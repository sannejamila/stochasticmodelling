---
title: "Project 1 - Stochastic Modelling"
output: pdf_document
date: 'By: Sanne Jamila Razmara Olsen & Einride Brodahl Osland'
---
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",fig.width=4, fig.height=3,fig.align = "center")
```

__Problem 1__

For this problem we are analyzing an outbreak of measles. We use a simplified model where each individual can have in of the following states; susceptible (S), infected(I) and recovered/immune (R). Let $n = 0,1,2 ...$
denote time measured in days and assume that each day

1. A susceptible individual can become infected or remain susceptible
2. An infected individual can become recovered or remain infected,
3. A recovered individual can lose immunity and become susceptible, or remain recovered.

Assume that the individuals in the population are independent, and assume that for each day, any susceptible individual has a probability of $0 < \beta < 1$ of becoming infected tomorrow, any infected individual has a probability $0 < \gamma < 1$ of becoming recovered tomorrow, and any recovered individual has a probability $0 < \alpha < 1$ of losing immunity tomorrow.

a) 
Let $X_n$ denote the state of that individual at time $n$. Let the states 0, 1 and 2 correspond to S, I and R, respectively, and assume that $X_0 = 0$.

The Markov assumptions state that 

1. The probabilities of moving from one state to all others sum to one.
2. The probabilities apply to all system participants.
3. The probabilities are constant over time.
4. The states are independent over time.

We have that for an individual that is in the state susceptible (S) has a probability of $0 < \beta < 1$ of becoming infected tomorrow, and thus a probability of$0 < 1-\beta < 1$ of not becoming infected tomorrow. An individual of the state (S) can not become immune or recovered, as being susceptible is a contradiction to being immune and the susceptible individual has to become infected (I) before it can be recovered (R). Thus all the probabilities of moving from the state susceptible (S) sum to one. As the probability of becoming infected tomorrow is the same for any day as long as the individual is in state S, it is constant over time (not time-dependent). The same arguments hold for the other states as well. Thus the system $\{X_n : n = 0,1,...\}$ is a Markov chain.

Mark that a recovered/immune (individual in state (R)) or an infected individual (individual in state (I)) can not become susceptible (S). 

We have that for state 0 (being susceptible), there is a probability of $0 < \beta < 1$ of becoming infected tomorrow, and thus a probability of$0 < 1-\beta < 1$ of staying susceptible (staying in state $0$) tomorrow (not being infected). There is a $0$ probability of becoming recovered tomorrow (moving to state $3$).

Thus the first row of the transition probability matrix can be written as
$$\textbf{P}_1 =
\begin{bmatrix}
1-\beta & \beta & 0 
\end{bmatrix}
$$
We have that for state 1 (being infected), there is a probability of $0 < \gamma < 1$ of becoming recovered tomorrow, and thus a probability of$0 < 1-\gamma < 1$ of staying infected (staying in state $1$) tomorrow (not being recovered). There is a $0$ probability of becoming susceptible tomorrow (moving to state $0$).

Thus the second row of the transition probability matrix can be written as
$$\textbf{P}_2 =
\begin{bmatrix}
0 & 1-\gamma & \gamma
\end{bmatrix}
$$

For the second state (being recovered), there is a probability of $0 < \alpha < 1$ of becoming susceptible tomorrow, and thus a probability of$0 < 1-\alpha< 1$ of staying recovered (staying in state $2$) tomorrow (being recovered). There is a $0$ probability of becoming infected tomorrow (moving to state $1$).

Thus the third row of the transition probability matrix can be written as

$$\textbf{P}_3 =
\begin{bmatrix}
\alpha & 0 & 1- \alpha
\end{bmatrix}$$

Such that the full transition matrix can be written as

$$
\textbf{P} =
\begin{bmatrix}
1-\beta & \beta & 0\\ 
0 & 1-\gamma  & \gamma  \\
\alpha & 0 & 1-\alpha
\end{bmatrix}
$$
b) Assume $\beta = 0.01$, $\gamma = 0.1$ and $\alpha = 0.005$. We can thus write our transition matrix as
$$
\textbf{P} =
\begin{bmatrix}
0.99 & 0.01 & 0\\ 
0 & 0.9  & 0.1  \\
0.005 & 0 & 0.995
\end{bmatrix}
$$
We have that

$$
\textbf{P}^2 =
\begin{bmatrix}
0.9801 & 0.0189 & 0.001\\ 
0.005 & 0.81  & 0.1895  \\
0.00995 & 0.005 & 0.990025
\end{bmatrix}
$$
We know that the Markov chain is regular because $P_{ij}^2 > 0$ for all $i,j \in (0,1,2)$. Because $\{X_n : n = 0,1,2..\}$ is a regular Markov chain with state space $\{0,1,2\}$ and transition probability $\textbf{P}$, then there exists a limiting distribution $\pi = (\pi_0,\pi_1,\pi_2)$.

In a regular Markov chain $\{ X_n : n = 0,1,2...\}$ the limiting distribution $\pi = (\pi_0,\pi_1,\pi_2)$ gives the long-run mean fraction of time spent in each state.

We find these by solving the system $P \pi = \pi$.

We also have that $\pi_1 + \pi_2 + \pi_3 = 1$.

Choosing the following equations 

$$
0.99\pi_1 + 0.01\pi_2 = \pi_1
$$
$$
0.9\pi_2 + 0.1\pi_3 = \pi_2
$$
$$
0.005\pi_1 + 0.995\pi_3 = \pi_3
$$
$$\pi_1 + \pi_2 + \pi_3 = 1$$


We obtain the solution $\pi_1 = \frac{10}{31}, \pi_2 = \frac{1}{31}$ and $\pi_3 = \frac{20}{31}$. Thus the long-run mean number of days per year spent in each state is $118$ days susceptible, $12$ days infected and $235$ recovered.

c)


```{r, echo=FALSE}
simulate <- function(P, iter){
  #Finding the number of rows of P
  n <- nrow(P)
  #Initializing vector of the states, iter states
  states <- numeric(iter)
  
  #Assumption X_0 = 0
  states[1] <- 1
  
  #Simulating Markov chain
  for(t in 2:iter){
    #Probability vector to simulate next state (X_t+1)
    p <- P[states[t-1],]
    #Draw from multinomial distrubution to choose next state
    states[t] <- which(rmultinom(1,1,p) == 1)
  }
  return(states)
}

beta = 0.01
gamma = 0.1
alpha  = 0.005

P = matrix(c(1-beta,beta,0,0,1-gamma,gamma,alpha,0,1-alpha),nrow = 3, byrow = TRUE)


#State 0,1,2 transformed to state 1,2,3
n = 7300

states <- simulate(P,n)
```

```{r,echo=FALSE}

limiting_probs <- function(states){
  n = length(states)
  p1=0
  p2 = 0
  p3 = 0

  for(i in states){
    if(i == 1){
      p1 = p1 +1
    }
    else if(i == 2){
      p2 = p2 +1
    }
    else{
      p3 = p3 +1
    }
  }
  p1 = p1/n
  p2 = p2/n 
  p3 = p3/n

  pi <- c(p1,p2,p3)
  return(pi)
}

```

```{r, echo=FALSE}

test_states = states[3650:7300]
pi = limiting_probs(test_states)
```

```{r,eval=TRUE}
pi
```

```{r,echo=FALSE}
confidence_interval <- function(P,N,j){
  pi = numeric(N)
  
  for(i in 0:N){
    states = simulate(P,7300)
    states = states[3650:7300]
    
    pi[i] <- limiting_probs(states)[j]
    
  }
  n = N
  
  t = qt(0.95,df = n-1)
  
  variance = var(pi)
  mean = mean(pi)
  
  S = sqrt(n/(n-1)*variance)
  
  a = mean + t*S/sqrt(n)
  b = mean - t*S/sqrt(n) 
  
  return(c(a,b))
}

```

Assuming that the means of the simulated limiting probabilities are uniformly distributed, we consider the student-t distribution for computing our $95$% confidence intervals. 

Let $S_i^2 = \frac{1}{n-1} \sum_{j=0}^N(\pi_{ij}-\bar X_{ij})2$ denote the sample variance and let $\bar X_i$ denote the mean of the $\pi_i$ for the iÂ´th limiting probability our confidence interval is then given by

$$
\pi_i \in [\bar X_i-t_\alpha \frac{S_i}{\sqrt{n}},\bar X_i+t_\alpha \frac{S_i}{\sqrt{n}}]
$$

Where $t_\alpha$ is the critical value of the student-t distribution.

Implementing our solution in R (view document code.rmd) we obtain the simulated confidence intervals for our limiting probabilities.

```{r,eval=TRUE}
confidence_interval(P,30,1)
```

```{r,eval=TRUE}
confidence_interval(P,30,2)
```

```{r,eval=TRUE}
confidence_interval(P,30,3)
```
Which are close to our analytical solution od$\pi_1 = \frac{10}{31}, \pi_2 = \frac{1}{31}$ and $\pi_3 = \frac{20}{31}$, but noting that the intervals are quite high. 

d) 
e)
f)
g)

__Problem 2__

We have that $X(t)$ is the number of claims recieved by an insurance company in the time interval $[0,t]$. Assuming that $\{X(t) : t \ge 0\}$ can be modeled as a Poisson process, were $t$ is measured in days since January 1st at 00:00:00, assume that the rate of the Poisson process is given by $\lambda(t) = 1.5, t \ge 0$.

a) We want to compute the probability that there are more than $100$ claims at March 1 at 00:00:00. In other words, after 59 days.

We want to compute $P(X(59) > 100)$.

We have that $X(t) \sim Poisson(\lambda t)$ such that after $t = 59$ days the probability of $X_{59} > 100$ is given by

$$
P(X_{59} > 100) = 1- P(X_{59} \ge 100) = 1- \sum_{n=0}^{100} P(X_{59} = 100) = 1- \sum_{n=0}^{100} \frac{(59\lambda)^n}{n!} \exp(-59\lambda)\approx 
$$


```{r, echo=FALSE}

Poisson_Process <- function(lambda,n,t){
  #Creating empty vector of size n+1
  v<-numeric(n+1)
  v[1] <-0


  for (k in 1:n){
    x <- rpois(1,lambda*t)
    if(x > 100){
      v[k] = 1 
    }
    else{
      v[k] = 0
    }
    
  }
  return(v)
}

t <- 59
n <- 1000
lambda <-1.5

```

```{r, echo=FALSE}
#install.packages("RColorBrewer")
library(RColorBrewer)


plot_poisson <-function(t_value,lambda,N){
  #Creating colour palette to visualize simulations
  colour_palette = brewer.pal(n=10, name = "BrBG")
  #Generating plot to fill with simulation plots
  plot(NULL, NULL, xlim = c(0, t_value), ylim = c(0, 100), xlab = "Time", ylab = "Events", main = "Realization", lwd = 2)



  #Simulating N Poisson processes and plotting them by using lines() function
  for (n in 0:N) {
    #Picking from Poisson distribution
    X <- rpois(1, lambda * t_value)
    x = c(0:X, X)
  
    t <- runif(X, 0, t_value)
    t = c(0, sort(t), t_value)
    l = length(x)
    
    for (i in 1:(l - 1)){
      lines(t[i:(i + 1)], rep(x[i], 2), lwd = 2, col = colour_palette [n]) #Adding simulation to plot
    }
  }
}


#Initializing given values
t_value <- 59
lambda <- 1.5
N <- 9

```

```{r,eval=TRUE}

plot_poisson(t_value,lambda,N) 
```



b)


c)

